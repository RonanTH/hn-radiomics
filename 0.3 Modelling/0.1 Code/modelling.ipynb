{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules & Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "import logging\r\n",
    "logging.getLogger().setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General modules & loading data\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import pingouin as pg\r\n",
    "import os\r\n",
    "from tqdm import tqdm, tqdm_gui\r\n",
    "\r\n",
    "from wrapperfunctions import *\r\n",
    "\r\n",
    "# Model Modules\r\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 30\r\n",
    "pd.options.display.max_columns = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_timepoint_wrapper(data, clf,timepoints, save_location,reps = 1,clinical_model=False, silent=True):\r\n",
    "\r\n",
    "    times = timepoints\r\n",
    "    \r\n",
    "    results = {'basic': [apply_single_clf(clf, data,repeat =reps,save_location = save_location, timepoint=t, apply_feature_selection=False, bagging=False, silent=silent) for t in times],\r\n",
    "                'feature_selection': [apply_single_clf(clf, data,repeat =reps,save_location = save_location, timepoint=t, apply_feature_selection=True, bagging=False, silent=silent) for t in times],\r\n",
    "                'bagging':[apply_single_clf(clf, data,repeat =reps,save_location = save_location, timepoint=t, apply_feature_selection=False, bagging=True, silent=silent) for t in times],\r\n",
    "                }\r\n",
    "\r\n",
    "    df = pd.DataFrame()\r\n",
    "\r\n",
    "    for i in list(results.keys()):\r\n",
    "        for j in range(len(times)):\r\n",
    "            df=df.append(results[i][j]['test_result']).reset_index(drop=True)\r\n",
    "            # if not clinical_model:\r\n",
    "            #     plot_km(results[i][j],data,folder='Naive Bayes',save_path = kaplan_saves)\r\n",
    "            \r\n",
    "    df.sort_values(by='timepoint',inplace=True)\r\n",
    "    \r\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_timepoint_wrapper(data, clf,save_location,clinical_model=False, silent=True, reps=1):\r\n",
    "\r\n",
    "    \r\n",
    "    results = {'basic': apply_multi_clf(clf, data, save_location ,repeat=reps, apply_feature_selection=False, bagging=False, silent=silent) ,\r\n",
    "                'feature_selection': apply_multi_clf(clf, data, save_location,repeat=reps, apply_feature_selection=True, bagging=False, silent=silent),\r\n",
    "                'bagging':apply_multi_clf(clf, data,save_location, repeat=reps, apply_feature_selection=False, bagging=True, silent=silent),\r\n",
    "                }\r\n",
    "\r\n",
    "    df = pd.DataFrame()\r\n",
    "\r\n",
    "    for i in list(results.keys()):\r\n",
    "        df=df.append(results[i]['results_df']).reset_index(drop=True)\r\n",
    "        # if not clinical_model:\r\n",
    "        #     plot_km(results[i],data,folder='Naive Bayes',save_path = kaplan_saves)\r\n",
    "            \r\n",
    "    # df.sort_values(by='timepoint',inplace=True)\r\n",
    "    \r\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data & Applying Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Perform Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = ['t1','t2']\r\n",
    "rnd_state = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\r\n",
    "\r\n",
    "project_root =  os.path.dirname(os.path.dirname(cwd))\r\n",
    "feat_output_path = os.path.join(project_root,'0.1 Feature Extraction/0.2 Outputs/0.1 Extracted Features')\r\n",
    "\r\n",
    "output_path = os.path.join(project_root, '0.3 Modelling/0.2 Outputs')\r\n",
    "split_eval_saves = os.path.join(output_path, '0.4 Split Tests')\r\n",
    "\r\n",
    "scores_saves = os.path.join(output_path, '0.1 Scores')\r\n",
    "rad_confusion_saves = os.path.join(output_path, '0.2 Confusion Matrices/Radiomics Models')\r\n",
    "clinical_confusion_saves = os.path.join(output_path, '0.2 Confusion Matrices/Clinical Models')\r\n",
    "kaplan_saves = os.path.join(output_path, '0.3 Kaplan Meier Graphs')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "clinical_data_path = os.path.join(project_root, '0.4 Clinical Data Processing/0.2 Data')\r\n",
    "\r\n",
    "image_feats = {'t1': pd.read_csv( os.path.join(feat_output_path, 'T1/Merged_Features_T1.csv')),'t2': pd.read_csv( os.path.join(feat_output_path, 'T2/Merged_Features_T2.csv'))}\r\n",
    "\r\n",
    "split_data = {'t1':train_test_split(image_feats['t1'], random_state=rnd_state), 't2':train_test_split(image_feats['t2'], random_state=rnd_state)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse split for significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data_wb = pd.ExcelFile(os.path.join(clinical_data_path,'clinical_data.xlsx'))\r\n",
    "clinical_data = clinical_data_wb.parse('Clinical Data')\r\n",
    "\r\n",
    "clinical_data.drop(['Patient Data'], axis =1, inplace=True)\r\n",
    "clinical_data[\"split_group\"] = np.nan\r\n",
    "clinical_data.loc[clinical_data['PID'].isin(split_data['t1']['train_pids'].tolist()),'split_group'] = 'Train'\r\n",
    "clinical_data.loc[clinical_data['PID'].isin(split_data['t1']['test_pids'].tolist()),'split_group'] = 'Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform t-tests on numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_analysis = {}\r\n",
    "numeric_analysis['train_stats'] = clinical_data.loc[clinical_data['PID'].isin(split_data['t1']['train_pids'].tolist())].describe()\r\n",
    "numeric_analysis['test_stats'] = clinical_data.loc[clinical_data['PID'].isin(split_data['t1']['test_pids'].tolist())].describe()\r\n",
    "numeric_tests = pd.DataFrame()\r\n",
    "for i in list(clinical_data.select_dtypes(include=[np.number]).columns):\r\n",
    "    temp_res = pg.pairwise_ttests(data=clinical_data, dv=i, between='split_group')\r\n",
    "    temp_res['Variable']= [i]\r\n",
    "    numeric_tests=numeric_tests.append(temp_res,ignore_index=True)\r\n",
    "numeric_analysis['t_tests'] = numeric_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform chi-squared tests on categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_tests = {}\r\n",
    "categories = ['Gender','Diabetes','Drinker','Smoker','Final Stage','Ground Truth']\r\n",
    "for i in categories:\r\n",
    "    chi_tests[i] = pg.chi2_independence(data=clinical_data,x=i,y='split_group',correction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirm_save = input(\"Are you sure you wish to save results (may overwrite existing results)? y/n\")\r\n",
    "\r\n",
    "if confirm_save =='y':  \r\n",
    "    save_stats_tests(chi_tests, numeric_analysis, split_eval_saves)\r\n",
    "\r\n",
    "else:\r\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Classifier Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\r\n",
    "learning_rate=0.05\r\n",
    "max_jobs = 18\r\n",
    "reps=100\r\n",
    "\r\n",
    "naive_bayes_params = {}\r\n",
    "\r\n",
    "ada_boost_params = {'n_estimators': n_estimators,\r\n",
    "                    'learning_rate':1,\r\n",
    "                    }\r\n",
    "\r\n",
    "grad_boost_params = {'n_estimators':n_estimators,\r\n",
    "                     'learning_rate':1,\r\n",
    "                     }\r\n",
    "\r\n",
    "xgb_params = {'objective': 'binary:logistic',\r\n",
    "              'eval_metric': 'auc', \r\n",
    "              'n_estimators': n_estimators, \r\n",
    "              'learning_rate': learning_rate,\r\n",
    "              'use_label_encoder': False, \r\n",
    "              'max_depth': 15, \r\n",
    "              'n_jobs': max_jobs,\r\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radiomics Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier: 100%|██████████| 100/100 [01:22<00:00,  1.21it/s]\n",
      "AdaBoostClassifier: 100%|██████████| 100/100 [01:24<00:00,  1.18it/s]\n",
      "AdaBoostClassifier + Feature Selection: 100%|██████████| 100/100 [00:15<00:00,  6.39it/s]\n",
      "AdaBoostClassifier + Feature Selection: 100%|██████████| 100/100 [00:15<00:00,  6.28it/s]\n",
      "AdaBoostClassifier + Bagging: 100%|██████████| 100/100 [03:42<00:00,  2.23s/it]\n",
      "AdaBoostClassifier + Bagging: 100%|██████████| 100/100 [03:40<00:00,  2.21s/it]\n",
      "GaussianNB: 100%|██████████| 100/100 [00:00<00:00, 113.61it/s]\n",
      "GaussianNB: 100%|██████████| 100/100 [00:00<00:00, 113.81it/s]\n",
      "GaussianNB + Feature Selection: 100%|██████████| 100/100 [00:03<00:00, 31.73it/s]\n",
      "GaussianNB + Feature Selection: 100%|██████████| 100/100 [00:03<00:00, 29.48it/s]\n",
      "GaussianNB + Bagging: 100%|██████████| 100/100 [00:13<00:00,  7.51it/s]\n",
      "GaussianNB + Bagging: 100%|██████████| 100/100 [00:12<00:00,  8.00it/s]\n",
      "GradientBoostingClassifier: 100%|██████████| 100/100 [01:55<00:00,  1.15s/it]\n",
      "GradientBoostingClassifier: 100%|██████████| 100/100 [02:05<00:00,  1.25s/it]\n",
      "GradientBoostingClassifier + Feature Selection: 100%|██████████| 100/100 [00:05<00:00, 16.89it/s]\n",
      "GradientBoostingClassifier + Feature Selection: 100%|██████████| 100/100 [00:06<00:00, 15.29it/s]\n",
      "GradientBoostingClassifier + Bagging: 100%|██████████| 100/100 [02:09<00:00,  1.29s/it]\n",
      "GradientBoostingClassifier + Bagging: 100%|██████████| 100/100 [02:07<00:00,  1.27s/it]\n",
      "XGBClassifier: 100%|██████████| 100/100 [00:16<00:00,  5.98it/s]\n",
      "XGBClassifier: 100%|██████████| 100/100 [00:15<00:00,  6.33it/s]\n",
      "XGBClassifier + Feature Selection: 100%|██████████| 100/100 [00:05<00:00, 17.51it/s]\n",
      "XGBClassifier + Feature Selection: 100%|██████████| 100/100 [00:06<00:00, 16.49it/s]\n",
      "XGBClassifier + Bagging: 100%|██████████| 100/100 [03:53<00:00,  2.33s/it]\n",
      "XGBClassifier + Bagging: 100%|██████████| 100/100 [03:55<00:00,  2.35s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfs = [AdaBoostClassifier(**ada_boost_params),\r\n",
    "        GaussianNB(**naive_bayes_params),\r\n",
    "        GradientBoostingClassifier(**grad_boost_params),\r\n",
    "        xgb.XGBClassifier(**xgb_params)]\r\n",
    "\r\n",
    "rad_single_results = pd.DataFrame()\r\n",
    "\r\n",
    "for clf in clfs:\r\n",
    "    rad_single_results =rad_single_results.append(single_timepoint_wrapper(split_data,clf,timepoints, save_location = rad_confusion_saves, reps=reps),ignore_index=True)\r\n",
    "rad_single_results.sort_values(['timepoint','model'],inplace=True)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier: 100%|██████████| 100/100 [02:35<00:00,  1.56s/it]\n",
      "AdaBoostClassifier + Feature Selection: 100%|██████████| 100/100 [00:25<00:00,  3.85it/s]\n",
      "AdaBoostClassifier + Bagging: 100%|██████████| 100/100 [04:17<00:00,  2.58s/it]\n",
      "GaussianNB: 100%|██████████| 100/100 [00:01<00:00, 76.57it/s]\n",
      "GaussianNB + Feature Selection: 100%|██████████| 100/100 [00:05<00:00, 17.23it/s]\n",
      "GaussianNB + Bagging: 100%|██████████| 100/100 [00:18<00:00,  5.46it/s]\n",
      "GradientBoostingClassifier: 100%|██████████| 100/100 [04:00<00:00,  2.40s/it]\n",
      "GradientBoostingClassifier + Feature Selection: 100%|██████████| 100/100 [00:11<00:00,  8.64it/s]\n",
      "GradientBoostingClassifier + Bagging: 100%|██████████| 100/100 [03:33<00:00,  2.14s/it]\n",
      "XGBClassifier: 100%|██████████| 100/100 [00:29<00:00,  3.36it/s]\n",
      "XGBClassifier + Feature Selection: 100%|██████████| 100/100 [00:10<00:00,  9.43it/s]\n",
      "XGBClassifier + Bagging: 100%|██████████| 100/100 [06:23<00:00,  3.83s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>mode</th>\n      <th>accuracy</th>\n      <th>AUC</th>\n      <th>PR_score</th>\n      <th>f1_score</th>\n      <th>fb_score</th>\n      <th>MCC_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AdaBoostClassifier</td>\n      <td>base</td>\n      <td>0.915000</td>\n      <td>0.619687</td>\n      <td>0.322778</td>\n      <td>0.382857</td>\n      <td>0.282043</td>\n      <td>0.456319</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AdaBoostClassifier + Feature Selection</td>\n      <td>feature selection</td>\n      <td>0.844167</td>\n      <td>0.669531</td>\n      <td>0.253543</td>\n      <td>0.328304</td>\n      <td>0.385475</td>\n      <td>0.276591</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AdaBoostClassifier + Bagging</td>\n      <td>bagging</td>\n      <td>0.907778</td>\n      <td>0.876953</td>\n      <td>0.742030</td>\n      <td>0.259619</td>\n      <td>0.198779</td>\n      <td>0.298221</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>GaussianNB</td>\n      <td>base</td>\n      <td>0.500000</td>\n      <td>0.574219</td>\n      <td>0.341270</td>\n      <td>0.181818</td>\n      <td>0.294118</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GaussianNB + Feature Selection</td>\n      <td>feature selection</td>\n      <td>0.827778</td>\n      <td>0.594063</td>\n      <td>0.302473</td>\n      <td>0.203472</td>\n      <td>0.215253</td>\n      <td>0.128088</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GaussianNB + Bagging</td>\n      <td>bagging</td>\n      <td>0.661111</td>\n      <td>0.603789</td>\n      <td>0.353128</td>\n      <td>0.151065</td>\n      <td>0.206742</td>\n      <td>-0.011600</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>GradientBoostingClassifier</td>\n      <td>base</td>\n      <td>0.888889</td>\n      <td>0.703984</td>\n      <td>0.304849</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GradientBoostingClassifier + Feature Selection</td>\n      <td>feature selection</td>\n      <td>0.888889</td>\n      <td>0.765000</td>\n      <td>0.251103</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GradientBoostingClassifier + Bagging</td>\n      <td>bagging</td>\n      <td>0.893889</td>\n      <td>0.959570</td>\n      <td>0.783339</td>\n      <td>0.090095</td>\n      <td>0.070984</td>\n      <td>0.097939</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>XGBClassifier</td>\n      <td>base</td>\n      <td>0.833333</td>\n      <td>0.808594</td>\n      <td>0.349206</td>\n      <td>0.500000</td>\n      <td>0.625000</td>\n      <td>0.448833</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>XGBClassifier + Feature Selection</td>\n      <td>feature selection</td>\n      <td>0.836111</td>\n      <td>0.728984</td>\n      <td>0.279330</td>\n      <td>0.418421</td>\n      <td>0.479595</td>\n      <td>0.342118</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XGBClassifier + Bagging</td>\n      <td>bagging</td>\n      <td>0.917500</td>\n      <td>0.973125</td>\n      <td>0.864271</td>\n      <td>0.371881</td>\n      <td>0.302013</td>\n      <td>0.403741</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                            model               mode  \\\n0                              AdaBoostClassifier               base   \n1          AdaBoostClassifier + Feature Selection  feature selection   \n2                    AdaBoostClassifier + Bagging            bagging   \n0                                      GaussianNB               base   \n1                  GaussianNB + Feature Selection  feature selection   \n2                            GaussianNB + Bagging            bagging   \n0                      GradientBoostingClassifier               base   \n1  GradientBoostingClassifier + Feature Selection  feature selection   \n2            GradientBoostingClassifier + Bagging            bagging   \n0                                   XGBClassifier               base   \n1               XGBClassifier + Feature Selection  feature selection   \n2                         XGBClassifier + Bagging            bagging   \n\n   accuracy       AUC  PR_score  f1_score  fb_score  MCC_Score  \n0  0.915000  0.619687  0.322778  0.382857  0.282043   0.456319  \n1  0.844167  0.669531  0.253543  0.328304  0.385475   0.276591  \n2  0.907778  0.876953  0.742030  0.259619  0.198779   0.298221  \n0  0.500000  0.574219  0.341270  0.181818  0.294118   0.000000  \n1  0.827778  0.594063  0.302473  0.203472  0.215253   0.128088  \n2  0.661111  0.603789  0.353128  0.151065  0.206742  -0.011600  \n0  0.888889  0.703984  0.304849  0.000000  0.000000   0.000000  \n1  0.888889  0.765000  0.251103  0.000000  0.000000   0.000000  \n2  0.893889  0.959570  0.783339  0.090095  0.070984   0.097939  \n0  0.833333  0.808594  0.349206  0.500000  0.625000   0.448833  \n1  0.836111  0.728984  0.279330  0.418421  0.479595   0.342118  \n2  0.917500  0.973125  0.864271  0.371881  0.302013   0.403741  "
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfs = [AdaBoostClassifier(**ada_boost_params),\r\n",
    "        GaussianNB(**naive_bayes_params),\r\n",
    "        GradientBoostingClassifier(**grad_boost_params),\r\n",
    "        xgb.XGBClassifier(**xgb_params)]\r\n",
    "\r\n",
    "\r\n",
    "rad_multi_results = pd.DataFrame()\r\n",
    "full_res =[]\r\n",
    "\r\n",
    "for clf in clfs:\r\n",
    "    temp_res = multi_timepoint_wrapper(split_data,clf,save_location = rad_confusion_saves,reps=reps)\r\n",
    "    rad_multi_results=rad_multi_results.append(temp_res)\r\n",
    "rad_multi_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "suv_data = clinical_data_wb.parse('SUVs')\r\n",
    "suv_data.drop(['Patient Data','T1 Date', 'T2 Date'], axis =1, inplace=True)\r\n",
    "split_suv_data = {'t1':clinical_train_test_split(suv_data[['PID', 'T1 Toncil SUV', 'T1 Liver SUV', 'T1 Normalised Toncil SUV', 'Response', 'Ground Truth']],random_state=rnd_state),\r\n",
    "                  't2':clinical_train_test_split(suv_data[['PID', 'T2 Toncil SUV', 'T2 Liver SUV', 'T2 Normalised Toncil SUV', '% Change in Toncil SUV', 'Response', 'Ground Truth']],random_state=rnd_state)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier: 100%|██████████| 100/100 [00:13<00:00,  7.57it/s]\n",
      "AdaBoostClassifier: 100%|██████████| 100/100 [00:13<00:00,  7.55it/s]\n",
      "AdaBoostClassifier + Feature Selection: 100%|██████████| 100/100 [00:13<00:00,  7.54it/s]\n",
      "AdaBoostClassifier + Feature Selection: 100%|██████████| 100/100 [00:13<00:00,  7.56it/s]\n",
      "AdaBoostClassifier + Bagging: 100%|██████████| 100/100 [02:39<00:00,  1.59s/it]\n",
      "AdaBoostClassifier + Bagging: 100%|██████████| 100/100 [02:39<00:00,  1.59s/it]\n",
      "GaussianNB: 100%|██████████| 100/100 [00:00<00:00, 156.67it/s]\n",
      "GaussianNB: 100%|██████████| 100/100 [00:00<00:00, 157.65it/s]\n",
      "GaussianNB + Feature Selection: 100%|██████████| 100/100 [00:00<00:00, 129.21it/s]\n",
      "GaussianNB + Feature Selection: 100%|██████████| 100/100 [00:00<00:00, 132.80it/s]\n",
      "GaussianNB + Bagging: 100%|██████████| 100/100 [00:07<00:00, 12.95it/s]\n",
      "GaussianNB + Bagging: 100%|██████████| 100/100 [00:07<00:00, 12.93it/s]\n",
      "GradientBoostingClassifier: 100%|██████████| 100/100 [00:03<00:00, 25.96it/s]\n",
      "GradientBoostingClassifier: 100%|██████████| 100/100 [00:03<00:00, 25.21it/s]\n",
      "GradientBoostingClassifier + Feature Selection: 100%|██████████| 100/100 [00:03<00:00, 27.96it/s]\n",
      "GradientBoostingClassifier + Feature Selection: 100%|██████████| 100/100 [00:03<00:00, 25.11it/s]\n",
      "GradientBoostingClassifier + Bagging: 100%|██████████| 100/100 [00:40<00:00,  2.45it/s]\n",
      "GradientBoostingClassifier + Bagging: 100%|██████████| 100/100 [00:41<00:00,  2.44it/s]\n",
      "XGBClassifier: 100%|██████████| 100/100 [00:03<00:00, 27.08it/s]\n",
      "XGBClassifier: 100%|██████████| 100/100 [00:03<00:00, 29.19it/s]\n",
      "XGBClassifier + Feature Selection: 100%|██████████| 100/100 [00:03<00:00, 27.81it/s]\n",
      "XGBClassifier + Feature Selection: 100%|██████████| 100/100 [00:03<00:00, 26.82it/s]\n",
      "XGBClassifier + Bagging: 100%|██████████| 100/100 [02:15<00:00,  1.36s/it]\n",
      "XGBClassifier + Bagging: 100%|██████████| 100/100 [02:16<00:00,  1.37s/it]\n",
      "100%|██████████| 4/4 [13:10<00:00, 197.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfs = [AdaBoostClassifier(**ada_boost_params),\r\n",
    "        GaussianNB(**naive_bayes_params),\r\n",
    "        GradientBoostingClassifier(**grad_boost_params),\r\n",
    "        xgb.XGBClassifier(**xgb_params)]\r\n",
    "\r\n",
    "clinical_single_timepoint = pd.DataFrame()\r\n",
    "\r\n",
    "for clf in tqdm(clfs):\r\n",
    "    clinical_single_timepoint =clinical_single_timepoint.append(single_timepoint_wrapper(split_suv_data,clf,timepoints=timepoints,clinical_model=True,save_location = clinical_confusion_saves, reps=reps),ignore_index=True)\r\n",
    "clinical_single_timepoint.sort_values(['timepoint','model'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier: 100%|██████████| 100/100 [00:20<00:00,  4.78it/s]\n",
      "AdaBoostClassifier + Feature Selection: 100%|██████████| 100/100 [00:20<00:00,  4.84it/s]\n",
      "AdaBoostClassifier + Bagging: 100%|██████████| 100/100 [02:15<00:00,  1.35s/it]\n",
      "GaussianNB: 100%|██████████| 100/100 [00:00<00:00, 133.51it/s]\n",
      "GaussianNB + Feature Selection: 100%|██████████| 100/100 [00:00<00:00, 106.35it/s]\n",
      "GaussianNB + Bagging: 100%|██████████| 100/100 [00:07<00:00, 12.93it/s]\n",
      "GradientBoostingClassifier: 100%|██████████| 100/100 [00:07<00:00, 13.57it/s]\n",
      "GradientBoostingClassifier + Feature Selection: 100%|██████████| 100/100 [00:06<00:00, 14.83it/s]\n",
      "GradientBoostingClassifier + Bagging: 100%|██████████| 100/100 [00:42<00:00,  2.33it/s]\n",
      "XGBClassifier: 100%|██████████| 100/100 [00:06<00:00, 15.50it/s]\n",
      "XGBClassifier + Feature Selection: 100%|██████████| 100/100 [00:06<00:00, 14.62it/s]\n",
      "XGBClassifier + Bagging: 100%|██████████| 100/100 [02:27<00:00,  1.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfs = [AdaBoostClassifier(**ada_boost_params),\r\n",
    "        GaussianNB(**naive_bayes_params),\r\n",
    "        GradientBoostingClassifier(**grad_boost_params),\r\n",
    "        xgb.XGBClassifier(**xgb_params)]\r\n",
    "\r\n",
    "clinicla_multi_results = pd.DataFrame()\r\n",
    "full_res =[]\r\n",
    "for clf in clfs:\r\n",
    "    temp_res = multi_timepoint_wrapper( split_suv_data,clf,save_location = clinical_confusion_saves, reps=reps)\r\n",
    "    clinicla_multi_results=clinicla_multi_results.append(temp_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirm_save = input(\"Are you sure you wish to save results (may overwrite existing results)? y/n\")\r\n",
    "\r\n",
    "if confirm_save =='y':\r\n",
    "\r\n",
    "    writer = pd.ExcelWriter(os.path.join(scores_saves,'classifier_scores.xlsx'), engine='xlsxwriter')\r\n",
    "\r\n",
    "    rad_single_results.to_excel(writer, sheet_name='Radiomics ST Models')\r\n",
    "    rad_multi_results.to_excel(writer, sheet_name='Radiomics MT Models')\r\n",
    "    clinical_single_timepoint.to_excel(writer, sheet_name='Clinical ST Models')\r\n",
    "    clinicla_multi_results.to_excel(writer, sheet_name='Clinical MT Models')\r\n",
    "    writer.save()\r\n",
    "    \r\n",
    "else:\r\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clfs = [GaussianNB(),\r\n",
    "#         AdaBoostClassifier(),\r\n",
    "#         GradientBoostingClassifier(),\r\n",
    "#         xgb.XGBClassifier(objective='binary:logistic', eval_metric = 'auc', n_estimators= 100, learning_rate=0.01,use_label_encoder=False, max_depth=15, n_jobs=18)]\r\n",
    "\r\n",
    "# clinical_results = pd.DataFrame()\r\n",
    "\r\n",
    "# for clf in tqdm(clfs):\r\n",
    "#     clinical_results =clinical_results.append(single_timepoint_wrapper(split_suv_data,clf, clinical_model=True),ignore_index=True)\r\n",
    "# clinical_results.sort_values(['timepoint','model'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = Lasso()\r\n",
    "\r\n",
    "# xgb_results = {'basic': [apply_single_clf(clf, split_data, timepoint=t, apply_feature_selection=False, bagging=False, silent=True) for t in timepoints],\r\n",
    "#               'feature_selection': [apply_single_clf(clf, split_data, timepoint=t, apply_feature_selection=True, bagging=False, silent=True) for t in timepoints],\r\n",
    "#               'bagging':[apply_single_clf(clf, split_data, timepoint=t, apply_feature_selection=False, bagging=True, silent=True) for t in timepoints],\r\n",
    "#               }\r\n",
    "\r\n",
    "# xgb_df = pd.DataFrame()\r\n",
    "\r\n",
    "# for i in list(xgb_results.keys()):\r\n",
    "#     for j in range(len(timepoints)):\r\n",
    "#         xgb_df=xgb_df.append(xgb_results[i][j]['test_result']['results_df']).reset_index(drop=True)\r\n",
    "#         plot_km(xgb_results[i][j],split_data,folder='SVC',save_path = kaplan_saves)\r\n",
    "# xgb_df.sort_values(by='timepoint',inplace=True)\r\n",
    "      \r\n",
    "# display(xgb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter(os.path.join(split_eval_saves,'split_evaluation.xlsx'), engine='xlsxwriter')\r\n",
    "\r\n",
    "# mann_whit_tests = \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# single_timepoint_results.to_excel(writer, sheet_name='Radiomics ST Models')\r\n",
    "# results.to_excel(writer, sheet_name='Radiomics MT Models')\r\n",
    "# clinical_results.to_excel(writer, sheet_name='Clinical Models')\r\n",
    "# writer.save()\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "name": "python386jvsc74a57bd0615a7dda892719774096587b3a7293a99c271efcca0a9ce908482d067af6d18b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "615a7dda892719774096587b3a7293a99c271efcca0a9ce908482d067af6d18b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}